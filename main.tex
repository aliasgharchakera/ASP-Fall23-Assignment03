\documentclass[answers]{exam}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{geometry}
\usepackage{venndiagram}
\usepackage{graphics}
\usepackage{graphicx}
\usepackage{tikz}
\usetikzlibrary{shapes.geometric}

% Header and footer.
\pagestyle{headandfoot}
\runningheadrule
\runningfootrule
\runningheader{Applied Stochastic Processes}{Assignment 3}{Fall 2023 }
\runningfooter{}{Page \thepage\ of \numpages}{}
\firstpageheader{}{}{}

\boxedpoints
\printanswers

\newcommand{\uvec}[1]{\boldsymbol{\hat{\textbf{#1}}}}
\newcommand\union\cup
\newcommand\inter\cap
\newcommand\ul\underline
\newcommand\ol\overline

\title{Assignment 3\\ Applied Stochastic Processes\\ Habib University -- Fall 2023}
\author{Ali Asghar Yousuf - ay06993 \\ Muhammad Murtaza - mm06369 }  % replace with your ID, e.g. oy02945
\date{\today}

\begin{document}
\maketitle
\section{Bertsekas and Tsitsiklis, Section 7.1}
\begin{questions}
    \question \textbf{Problem 2}

    Dave fails quizzes with probability $\dfrac{1}{4}$, independent of other
    quizzes.
    \begin{parts}
        \part What is the probability that Dave fails exactly two of the next six quizzes?
        \begin{solution}
            \begin{align*}
                P(\text{Dave fails exactly two of the next six quizzes}) & = \binom{6}{2} \left(\frac{1}{4}\right)^2 \left(\frac{3}{4}\right)^4 \\
                                                                         & = 15 \times \frac{1}{16} \times \frac{81}{256}                       \\
                                                                         & = \frac{1215}{4096}                                                  \\
                                                                         & = 0.296875
            \end{align*}
        \end{solution}
        \part What is the expected number of quizzes that Dave will pass before he has failed
        three times?
        \begin{solution}

            No. of times he failed $= 3$ \\ Total no. of quizzes taken to fail 3 times $=
                n$ \\
            \begin{align*}
                n * \frac{1}{4} = 3 \\
                n = 12
            \end{align*}
            Dave takes 12 quizzes to fail 3 times. Therefore, he passes 9 quizzes. \\
        \end{solution}
        \part What is the probability that the second and third time Dave fails a quiz will
        occur when he takes his eighth and ninth quizzes, respectively?
        \begin{solution}

            1st Fail $\rightarrow 1 - 7$ quizzes \\
            2nd Fail $\rightarrow 8$th quiz \\
            3rd Fail $\rightarrow 9$th quiz \\

            \begin{align*}
                P(X) & =P(\text{1 fail in 7 tests}) \cdot P(\text{2nd fail in 8th test}) \cdot P(\text{3rd fail in 9th test}) \\
                     & =\binom{7}{1}\left(\frac{1}{4}\right)^1 \left(\frac{3}{4}\right)^6 \cdot \frac{1}{4} \cdot \frac{1}{4} \\
                     & =\frac{7 \cdot 3^6}{4^9} = \frac{5103}{262144}                                                         \\
                     & =0.0194568634
            \end{align*}
        \end{solution}
        \part What is the probability that Dave fails two quizzes in a row before he passes two
        quizzes in a row?
        \begin{solution}

            $F =$ Fail, $P =$ Pass \\
            \begin{align*}
                P(X) & = P(\text{Dave fails two quizzes in a row before he passes two quizzes in a row})                                                                                 \\
                     & = P(FF \cup PFF \cup FPFF \cup PFPFF \cup FPFPFF \cup \dots)                                                                                                      \\
                     & = \dfrac{[P(F)]^2}{1 - P(F) \cdot P(P)} + \dfrac{P(P) \cdot [P(F)]^2}{1 - P(F) \cdot P(P)}                                                                        \\
                     & = \dfrac{\left(\frac{1}{4}\right)^2}{1 - \frac{1}{4} \cdot \frac{3}{4}} + \dfrac{\frac{3}{4} \cdot \left(\frac{1}{4}\right)^2}{1 - \frac{1}{4} \cdot \frac{3}{4}} \\
                     & = \dfrac{7}{52}
            \end{align*}

        \end{solution}
    \end{parts}

    \question \textbf{Problem 3}

    A computer system carries out tasks submitted by two users. Time is divided
    into slots. A slot can be idle, with probability $P_I = \frac{1}{6}$, and busy
    with probability $P_B = \frac{5}{6}$. During a busy slot, there is probability
    $P_{1 | B} = \frac{2}{5}$ (respectively, $P_{2 | B} = \frac{3}{5}$) that a task
    from user 1 (respectively, 2) is executed. We assume that events related to
    different slots are independent. \\ $T_1 = $ Task from user 1.

    \begin{parts}
        \part Find the probability that a task from user 1 is executed for the first time during
        the 4th slot.
        \begin{solution}
            During each slot, the probability of a task from user 1 is given by,

            \(p_1 = p_{1|B} \cdot p_B =(\frac{5}{6})  (\frac{2}{5}) = \frac{1}{3}\)

            Tasks from user 1 form a Bernoulli process and
            \begin{align*}
                P(T_1 \text{ is executed in 4th slot}) & = p_1 (1 - p_1)^3 = \dfrac{1}{3} \cdot \left(\dfrac{2}{3}\right)^3 \\
                                                       & = \dfrac{8}{81} = 0.0987654                                        \\
            \end{align*}
        \end{solution}

        \part Given that exactly 5 out of the first 10 slots were idle, find the probability that
        the 6th idle slot is slot 12.
        \begin{solution}
            Since exactly 5 out of the first 10 slots were idle, therefore, the 11th slot is busy. \\
            And since the slots are independent, \\
            \begin{align*}
                 & P(\text{6th idle slot is slot 12})                              \\
                 & = P(\text{11th slot is busy}) \cdot P(\text{12th slot is idle}) \\
                 & = \frac{5}{6} \times \frac{1}{6}                                \\
                 & = \frac{5}{36}                                                  \\
                 & = 0.138889
            \end{align*}
        \end{solution}

        \part Find the expected number of slots up to and including the 5th task from user 1.
        \begin{solution}
            Each slot contains a task from user 1 with probability $p_1 = \frac{1}{3}$, independent of other slots. The time of the 5th task from user 1 is a Pascal random variable of order 5, with parameter $p_1 = \frac{1}{3}$. Its mean is given by
            \begin{align*}
                \dfrac{5}{p_1} & = \dfrac{5}{1/3} = 15
            \end{align*}
        \end{solution}
        \part Find the expected number of busy slots up to and including the 5th task from
        user 1.
        \begin{solution}
            Each busy slot contains a task from user 1 with probability $p_{1|B} = \frac{2}{5}$, independent
            of other slots. The random variable of interest is a Pascal random variable of order 5,
            with parameter $p_{1|B} = \frac{2}{5}$. Its mean is
            \begin{align*}
                \dfrac{5}{p_{1 | B}} & = \dfrac{5}{2/5} = \dfrac{25}{2} = 12.5
            \end{align*}
        \end{solution}

        \part Find the PMF, mean, and variance of the number of tasks from user 2 until the
        time of the 5th task from user 1.
        \begin{solution}
            The number $T$ of tasks from user 2 until the 5th task from user 1 is the same as the
            number $B$ of busy slots until the 5th task from user 1, minus 5. The number of busy
            slots (“trials”) until the 5th task from user 1 (“success”) is a Pascal random variable
            of order 5, with parameter $p_{1|B} = \frac{2}{5}$. Thus,
            \begin{align*}
                p_B(t) & = \binom{t - 1}{4} \left(\dfrac{2}{5}\right)^5 \left(1 - \dfrac{2}{5}\right)^{t-5} & t = 5, 6, \dots \\
            \end{align*}
            Since $T = B - 5$, we have $p_T(t) = p_B(t + 5)$, and we obtain
            \begin{align*}
                p_r(t) & = \binom{t + 4}{4}  \left(\dfrac{2}{5}\right)^5 \left(1 - \dfrac{2}{5}\right)^{t} & t = 0, 1, \dots \\
            \end{align*}
            Using the formulas for the mean and the variance of the Pascal random variable $B$, we
            obtain
            \begin{align*}
                E[T] = E[B] - 5 = \dfrac{25}{2} - 5 = 7.5
            \end{align*}
            and
            \begin{align*}
                \text{Var}(T) = \text{Var}(B) = \dfrac{5 (1 - (2/5))}{(2/5)^2} = 18.75
            \end{align*}

        \end{solution}
    \end{parts}
\end{questions}

\section{Leon-Garcia, Section 11}
\begin{questions}
    \question \textbf{11.9}

    Let $X_n$ be an iid integer-valued random process. Show that $X_n$ is a Markov
    process and give its one-step transition probability matrix.
    \begin{solution}
        To show that random process $X_{n}$ is a markov process, I will show that the conditional probability distribution of the future states given present states depends only on the present state and not on sequence of previous states.
        \\~\\
        Let's denote the one-step transition probability matrix as $P$, where $P_{ij}$ = $P(X_{n+1} = j| X_{n} = i)$, i.e, the the probability of transitioning from state $i$ to state $j$ in one step.
        \\~\\
        Since $X_{n}$ is an iid. We have:
        \\
        $P(X_{n+1} = j| X_{n} = i,X_{n-1},X_{n-2},\ldots,X_{0} )$ = $P(X_{n+1} = j| X_{n} = i)$
        \\
        This is because $X_{n}$ being iid implies that the future values do not depend on the past values given the current state.
        \\
        Now let's compute $P_{ij}$, the probability of transitioning from state $i$ to state $j$ in one step.
        \\
        $P_{ij}$ = $P(X_{n+1} = j | X_{n} = i)$
        \\
        Since $X_{n}$ is iid, this probability is same for all $n$. Therefore we can simply denote it as $P(X_{1} = j | X_{0} = i)$ which is one step transition probability.
        \\
        So the one step transition probability matrix $P$ is given by

        \[
            P = \begin{bmatrix}
                P(X_1 = 1 | X_0 = 1) & P(X_1 = 2 | X_0 = 1) & \ldots \\
                P(X_1 = 1 | X_0 = 2) & P(X_1 = 2 | X_0 = 2) & \ldots \\
                \vdots               & \vdots               & \ddots
            \end{bmatrix}
        \]
        This matrix will contain the probabilities of transitioning from one state to
        another in one step, and the independence of the random variables ensures that
        $x_{n}$ is a Markov process.

    \end{solution}

    \question \textbf{11.20}

    A certain part of a machine can be in two states: working or undergoing repair.
    A working part fails during the course of a day with probability $a$. A part
    undergoing repair is put into working order during the course of a day with
    probability b. Let $X_{n}$ be the state of the part.
    \begin{parts}
        \part Show that $X_{n}$ is a two-state Markov chain and give its one-step transition probability matrix $P$.
        \begin{solution}
            Let $X_{n}$ be the state of the part at time $n$. To show that $X_{n}$ is a two state markov chain, we need to demonstrate that the probability of transitioning to the next state depends only on the current state, and not on the sequence of events that preceded it.
            \\
            For a one step transition probability matrix $P$, its entries are given by:
            \begin{center}
                $P_{ij} = P(X_{n+1} = j | X_{n} = i)$
            \end{center}

            The probability that a working part keeps working is:

            \begin{center}
                $P_{11} = P(X_{n+1} = 1 | X_{n} = 1) = 1 - a$
            \end{center}

            The probability that a part being repaired, remains under repair:

            \begin{center}
                $P_{22} = P(X_{n+1} = 2 | X_{n} = 2) = 1 - b$
            \end{center}

            The probability that a working part goes for repair is

            \begin{center}
                $P_{21} = P(X_{n+1} = 2 | X_{n} = 1) = a$
            \end{center}

            The probability that a part being repaired is restored:
            \begin{center}
                $P_{12} = P(X_{n+1} = 1 | X_{n} = 2) = b$
            \end{center}

            Therefore the one step transition probability matrix $P$ is

            \[
                P = \begin{bmatrix}
                    1 - a & a     \\
                    b     & 1 - b
                \end{bmatrix}
            \]
        \end{solution}

        \part Find the n-step transition probability matrix $P^{n}$.
        \begin{solution}

            The $n$-step transition probability matrix $P^n$ is given by:
            \[
                P^n = \underbrace{P \cdot P \cdot \ldots \cdot P}_{\text{n times}}
            \]

            The general formula for each element $P_{ij}^n$ in $P^n$ is obtained by
            considering all possible paths from state $i$ to state $j$ in $n$ steps. The
            $k$-th element of the resulting matrix is given by the sum of products of
            elements from corresponding positions in matrices $P^k$, where $k$ varies from
            1 to $n$. \\

            The $n$-step transition probability matrix $P^n$ is given by:
            \[
                P^n = \begin{bmatrix} (1 - a)^n + (ab)^n & a(1 - b)^n + (1 - a)b^n \\ b(1 - a)^n + (1 - b)a^n & (1 - b)^n + (ab)^n \end{bmatrix}
            \]
        \end{solution}

        \part Find the steady state probability for each of two states.
        \begin{solution}
            The steady state probability vector \(\pi\) satisfies the equation \(\pi P = \pi\), where \(\pi\) is a row vector. The steady state probabilities can be found by solving this system of equations.

            For the two-state Markov chain, the steady state probability vector \(\pi\) is:

            \[ \pi = \left( \frac{b}{a + b}, \frac{a}{a + b} \right) \]

            This vector represents the long-term proportion of time the system spends in
            each state.

        \end{solution}
    \end{parts}

    \question \textbf{11.22}

    A stochastic matrix is defined as a nonnegative matrix for which the elements
    of each row add to one.

    \begin{parts}
        \part Show that the transition probability matrix $P$ for a Markov chain is a stochastic matrix.
        \begin{solution}
            To show that the transition probability matrix $P$ for a Markov chain is a stochastic matrix, we need to demonstrate two things:

            \begin{enumerate}
                \item All elements of $P$ are nonnegative.
                \item The elements of each row of $P$ add up to one.
            \end{enumerate}

            Let $P = [p_{ij}]$ be the transition probability matrix for a Markov chain,
            where $p_{ij}$ represents the probability of transitioning from state $i$ to
            state $j$.

            \textbf{1. Nonnegativity:}
            For a stochastic matrix, all elements must be nonnegative. In the context of a transition probability matrix, probabilities must be between 0 and 1. Therefore, $0 \leq p_{ij} \leq 1$ for all $i, j$.

            \textbf{2. Row Sum:}
            The second condition is that the sum of the elements in each row of $P$ must be equal to 1. Mathematically, for each row $i$:
            \[ \sum_{j} p_{ij} = 1 \]

            This condition ensures that the system moves to a new state with certainty
            (probability 1) from the current state, reflecting the Markov property.

            Combining both conditions, we can say that $P$ is a stochastic matrix if and
            only if:
            \begin{enumerate}
                \item $p_{ij} \geq 0$ for all $i, j$.
                \item $\sum_{j} p_{ij} = 1$ for all $i$.
            \end{enumerate}

            Given that $P$ is a valid transition probability matrix, it satisfies both of
            these conditions and is therefore a stochastic matrix.

        \end{solution}

        \part Show that if $P$ and $Q$ are stochastic matrices, then $PQ$ is also a stochastic matrix.
        \begin{solution}
            To show that if $P$ and $Q$ are stochastic matrices, then $PQ$ is also a stochastic matrix, we need to verify the two conditions for a matrix to be stochastic:

            \begin{enumerate}
                \item All elements of $PQ$ are nonnegative.
                \item The elements of each row of $PQ$ add up to one.
            \end{enumerate}

            Let $P$ be an $m \times n$ matrix and $Q$ be an $n \times p$ matrix. The
            product $PQ$ is an $m \times p$ matrix.

            \textbf{1. Nonnegativity:}
            For each element $(PQ)_{ij}$ of $PQ$, it is obtained by taking the dot product of the $i$-th row of $P$ and the $j$-th column of $Q$. Since both $P$ and $Q$ are stochastic matrices, all their elements are nonnegative. The dot product of nonnegative vectors (rows of $P$ and columns of $Q$) will also be nonnegative. Therefore, all elements of $PQ$ are nonnegative.

            \textbf{2. Row Sum:}
            For each row $i$ of $PQ$, the sum of its elements $(PQ)_{ij}$ is given by the dot product of the $i$-th row of $P$ and all columns of $Q$. Since the row sums of $P$ and $Q$ are both equal to 1 (due to them being stochastic matrices), the dot product of the rows of $P$ with the columns of $Q$ will also have a sum equal to 1. Therefore, the elements of each row of $PQ$ add up to one.

            Combining both conditions, we can conclude that if $P$ and $Q$ are stochastic
            matrices, then $PQ$ is also a stochastic matrix.

        \end{solution}

        \part Show that if $P$ is a stochastic matrix, then $P^{n}$ is also a stochastic matrix.
        \begin{solution}
            To show that if $P$ is a stochastic matrix, then $P^n$ is also a stochastic matrix for any positive integer $n$, we need to verify the two conditions for a matrix to be stochastic:

            \begin{enumerate}
                \item All elements of $P^n$ are nonnegative.
                \item The elements of each row of $P^n$ add up to one.
            \end{enumerate}

            Let $P$ be an $m \times m$ stochastic matrix.

            \textbf{1. Nonnegativity:}
            Each element $(P^n)_{ij}$ of $P^n$ is obtained by taking the dot product of the $i$-th row of $P^n$ and the $j$-th column of $P^n$. Since $P$ is a stochastic matrix, all its elements are nonnegative. The dot product of nonnegative vectors (rows of $P^n$) will also be nonnegative. Therefore, all elements of $P^n$ are nonnegative.

            \textbf{2. Row Sum:}
            For each row $i$ of $P^n$, the sum of its elements $(P^n)_{ij}$ is given by the dot product of the $i$-th row of $P^n$ and all columns of $P^n$. We can express $P^n$ as the product $P \cdot P \cdot \ldots \cdot P$, where $P$ is multiplied by itself $n$ times.

            Since each row of $P$ adds up to one (as $P$ is stochastic), the dot product of
            the rows of $P^n$ with the columns of $P^n$ will also have a sum equal to 1.
            Therefore, the elements of each row of $P^n$ add up to one.

            Combining both conditions, we can conclude that if $P$ is a stochastic matrix,
            then $P^n$ is also a stochastic matrix for any positive integer $n$.
        \end{solution}

    \end{parts}

    \question{\textbf{11.23}}

    Show that if $P^k$ has identical rows, then $P^j$ has identical rows for all $j
        \geq k$.
    \begin{solution}
        Let \(P\) be a transition matrix with identical rows, and let \(P^k\) be the matrix obtained by multiplying \(P\) by itself \(k\) times.

        \(P^k = P\cdots P\)

        Since \(P\) has identical rows, the \(i\)th row of \(P\) is equal to the
        \(j\)th row of \(P\) for all \(i, j\).

        Therefore, the \(i\)th row of \(P^k\) is equal to the \(j\)th row of \(P^k\)
        for all \(i, j\).

        This implies that \(P^k\) has identical rows.

        Since \(P^k\) has identical rows, \(P^{k+1}\) must also have identical rows.

        This implies that \(P^j\) has identical rows for all \(j \geq k\).
    \end{solution}

    \question{\textbf{11.24}}

    Prove Eq. (11.14) by induction.

    \(P(n) = P^n\)
    \begin{solution}
        \begin{align*}
            P(1) & = P^1 = P                 \\
            P(2) & = P^2 = P \cdot P = P^2   \\
            P(3) & = P^3 = P \cdot P^2 = P^3 \\
            P(4) & = P^4 = P \cdot P^3 = P^4 \\
            \vdots
        \end{align*}

        The base case is \(P(1) = P^1 = P\).

        Assume that \(P(k) = P^k\) for some \(k \geq 1\).

        Then \(P(k+1) = P \cdot P^k = P^{k+1}\).

        Therefore, \(P(n) = P^n\) for all \(n \geq 1\) by induction.
    \end{solution}

    \question{\textbf{11.30}}

    Consider a random walk in the set $\{0, 1, \dots, M\}$ with transition
    probabilities

    \(p_{01} = 1, p_{M, M - 1} = 1, \text{ and } p_{i, i - 1} = q, p_{i, i + 1} = p \text{ for } i = 1, \dots, M - 1\)
    \begin{parts}
        \part Sketch the state transition diagram.
        \begin{solution}

            Since the transition probabilities of \(p_{01} \text{ and } p_{M, M - 1} =
            1\implies p_{10}\) and \(p_{M - 1, M} = 0\)

            Therefore, the state transition diagram is:

            \begin{tikzpicture}[->, >=stealth, auto, semithick, node distance=2cm]
                \tikzstyle{every state}=[fill=white,draw=black,thick,text=black,scale=1]
                \node[circle, draw]    (A)                     {$0$};
                \node[circle, draw]    (B)[right of=A]   {$1$};
                \node[circle, draw]    (C)[right of=B]   {$2$};
                \node    (D)[right of=C]   {$\cdots$};
                \node[ellipse, draw]    (E)[right of=D]   {$M-1$};
                \node[circle, draw]    (F)[right of=E]   {$M$};

                \path
                (A) edge[bend left]  node{$1$}         (B)
                % (B) edge[bend left]  node{$0$}         (A)
                (B) edge[bend left]  node{$p$}         (C)
                (C) edge[bend left]  node{$q$}         (B)
                % (E) edge[bend left]  node{$0$}         (F)
                (F) edge[bend left]  node{$1$}         (E)
                (C) edge[dotted]     node{}            (D)
                (D) edge[dotted]     node{}            (E);
            \end{tikzpicture}
        \end{solution}
    \end{parts}

    \question{\textbf{11.37}}

    Consider a Markov chain with state space and the following transition
    probabilities:

    \(P_{jj + 1} = a_j\) and \(p_{j1} = 1 - a_j\) where \(0 < a_j < 1\)
    \begin{parts}
        \part Sketch the state transition diagram.
        \begin{solution}

            \begin{tikzpicture}[->, >=stealth, auto, semithick, node distance=2cm]
                \tikzstyle{every state}=[fill=white, draw=black, thick, text=black, scale=1]

                % Define the states
                \node[circle, draw] (1) {$1$};
                \node[circle, draw] (2) [right of=1] {$2$};
                \node[circle, draw] (3) [right of=2] {$3$};
                \node        (dots) [right of=3] {$\cdots$};
                \node[ellipse, draw] (n-1) [right of=dots] {$n-1$};
                \node[circle, draw] (n) [right of=n-1] {$n$};
                \node (dots2) [right of=n, node distance=1cm] {$\cdots$};

                % Connect the states with arrows
                \draw (1) to[bend left] node[midway, above] {$a_1$} (2);
                \draw (2) to[bend left] node[midway, above] {$a_2$} (3);
                \draw (3) to[bend left] node[midway, above] {$a_3$} (dots);
                % \draw (dots) to[bend left] node[midway, above] {$a_{n-1}$} (n-1);
                \draw (n-1) to[bend left] node[midway, above] {$a_{n - 1}$} (n);

                \draw (2) to[bend left] node[above] {$1-a_2$} (1);
                \draw (3) to[bend left] node[midway, above] {$1-a_3$} (1);
                \draw (n-1) to[bend left] node[midway, above] {$1-a_{n-1}$} (1);
                \draw (n) to[bend left] node[midway, below] {$1-a_{n}$} (1);

                \draw (1) to[loop] node[midway, above] {$1-a_1$} (1);

            \end{tikzpicture}
        \end{solution}

        \part Determine whether the Markov chain is irreducible.
        \begin{solution}
            The Markov chain is irreducible if there is a path from every state to every
            other state. In this case, there is a path from every state to every other state
            with non zero probability. Therefore, the Markov chain is irreducible.
        \end{solution}
    \end{parts}

    \question{\textbf{11.41}}

    Consider the simple queueing system discussed in Example 11.36.
    \begin{parts}
        \part  Use the results in Example 11.36 to find the state transition probability matrix
        \begin{solution}
            From Ex 11.36 we have,

            \begin{align*}
                p_{o}{(t)} = \frac{\beta}{\alpha + \beta} + (p_{o}{(0)} - \frac{\beta}{\alpha + \beta}) e^{-(\alpha - \beta)t} \\
                p_{1}{(t)} = \frac{\beta}{\alpha + \beta} + (p_{1}{(0)} - \frac{\beta}{\alpha +
                    \beta}) e^{-(\alpha - \beta)t}
            \end{align*}

            Now if we suppose the initial state is 0, then $p_{0}(0) = 1 \implies$
            \begin{align*}
                p_{00}(t) & = \frac{\beta}{\alpha + \beta} + (1 - \frac{\beta}{\alpha + \beta})
                e^{-(\alpha - \beta)t} = \frac{\beta + \alpha e^{-(\alpha + \beta)t}}{\alpha +
                \beta}                                                                          \\
                p_{01}(t) & = 1 - p_{00}(t) = \frac{\alpha(1-e^{-(\alpha+\beta)t})}{\alpha +
                \beta}
            \end{align*}
            If the initial state is 1, then $p_{1}(0) = 1 \implies$
            \begin{align*}
                p_{11}(t) & = \frac{\alpha}{\alpha + \beta} + (1 + \frac{\alpha}{\alpha +
                    \beta})e^{-(\alpha + \beta)t} = \frac{\alpha + \beta e^{-(\alpha +
                \beta)t}}{\alpha + \beta}                                                                                                  \\
                p_{10}(t) & = 1 - p_{11}(t) = \frac{\beta(1-e^{-(\alpha+\beta)t})}{\alpha+\beta}                                           \\
                P(t)      & = \frac{1}{\alpha + \beta} \begin{bmatrix}
                                                           \beta + \alpha e^{-(\alpha+\beta)t} & \alpha(1 - e^{-(\alpha + \beta)t})    \\
                                                           \beta (1 - e^{-(\alpha + \beta)t})  & \alpha + \beta e^{-(\alpha + \beta)t}
                                                       \end{bmatrix}
            \end{align*}
        \end{solution}

        \part Find the following probabilities:

        \begin{align*}
            P[X(1.5) = 1, X(3) = 1 | X(0) = 0] \\
            P[X(1.5) = 1, X(3) = 1]
        \end{align*}

        \begin{solution}

            \begin{align*}
                                        & = P[X(3) = 1 | X(1.5) = 1, X(0) = 0] P[X(1.5) = 1 | X(0) = 0]                                                                              \\
                                        & = P[X(3) = 1 | X(1.5) = 1]P[X(1.5) = 1 | X(0) = 0]                                                                                         \\
                                        & = p_{11}(1.5) p_{01}(1.5)                                                                                                                  \\
                P[X(1.5) = 1, X(3) = 1] & = P[X(3)=1|X(1.5) = 1]P[X(1.5)=1]                                                                                                          \\
                                        & = p_{11}(1.5)\left[\dfrac{\alpha}{\alpha + \beta} + \left(p_{1}(0) - \dfrac{\alpha}{\alpha + \beta}\right)e ^{-(\alpha + \beta)1.5}\right]
            \end{align*}

        \end{solution}
    \end{parts}

    \question{\textbf{11.42}}

    A rechargeable battery in a depot is in one of three states: fully charged, in
    use, or recharging. Assume the mean time in each of these states is:
    $\frac{1}{\lambda}$; 1 hour; 3 hours. Batteries are not put into use unless
    they are fully charged.

    \begin{parts}
        \part Find a Markov model for the battery states and sketch the state transition diagram.
        \begin{solution}
            Let $X_n$ be the state of the battery at time $n$. The state space is $\{1, 2, 3\}$, where 1 represents the fully charged state, 2 represents the in use state, and 3 represents the recharging state. The transition probabilities are given by:

            \begin{align*}
                P_{12} & = 1 \\
                P_{23} & = 1 \\
                P_{31} & = 1
            \end{align*}

            The state transition diagram is:

            \begin{tikzpicture}[->, >=stealth, auto, semithick, node distance=2cm]
                \tikzstyle{every state}=[fill=white,draw=black,thick,text=black,scale=1]
                \node[circle, draw]    (A)                     {$1$};
                \node[circle, draw]    (B)[below right of=A]   {$2$};
                \node[circle, draw]    (C)[below left of=A]   {$3$};

                \path
                (A) edge[bend left]  node{$1$}         (B)
                (B) edge[bend left]  node{$1$}         (C)
                (C) edge[bend left]  node{$1$}         (A);
            \end{tikzpicture}

        \end{solution}

        \part Find the stationary pmf. Explain how the pmf varies with $\lambda$
        \begin{solution}
            The transition probability matrix \( P \) is given by:
            \[ P = \begin{bmatrix} 0 & 1 & 0 \\ 0 & 0 & 1 \\ 1 & 0 & 0 \end{bmatrix} \]
            
            Let \( \pi_1, \pi_2, \pi_3 \) be the stationary probabilities for states Fully Charged, In Use, and Recharging, respectively.
            
            The stationary distribution \( \pi \) satisfies the equation \( \pi P = \pi \). Solving for \( \pi \), we get:
            \[ \begin{bmatrix} \pi_1 & \pi_2 & \pi_3 \end{bmatrix} \begin{bmatrix} 0 & 1 & 0 \\ 0 & 0 & 1 \\ 1 & 0 & 0 \end{bmatrix} = \begin{bmatrix} \pi_1 & \pi_2 & \pi_3 \end{bmatrix} \]
            
            Now, let's consider the system of equations derived from the Markov chain:
            \begin{align*}
            1. & \quad \pi_1 = \pi_3 \\
            2. & \quad \pi_2 = \pi_1 \\
            3. & \quad \pi_3 = \pi_2
            \end{align*}
            
            Substituting \( \pi_1 = \pi_3 \) from equation (1) into equations (2) and (3):
            \begin{align*}
            2. & \quad \pi_2 = \pi_1 = \pi_3 \\
            3. & \quad \pi_3 = \pi_2 = \pi_1
            \end{align*}
            
            This implies that \( \pi_1 = \pi_2 = \pi_3 \), and a possible solution is \( \pi_1 = \frac{1}{3} \), \( \pi_2 = \frac{1}{3} \), \( \pi_3 = \frac{1}{3} \).
            
            As \( \lambda \) increases, the mean time in the fully charged state decreases. Therefore, the stationary probabilities \( \pi_1, \pi_2, \pi_3 \) are influenced by \( \lambda \), and an increase in \( \lambda \) would lead to a decrease in \( \pi_1 \) and an increase in \( \pi_2 \) and \( \pi_3 \). The system tends to distribute more time across the in-use and recharging states as \( \lambda \) increases.
            
                    \end{solution}

    \end{parts}
\end{questions}

\end{document}
